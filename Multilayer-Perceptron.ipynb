{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an implementation of a Multilyer Perceptron using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses the whole mnist dataset to try to learn a model that accurately predicts class labels for handwritten digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import os.path\n",
    "import scipy as sp\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and loading MNIST data\n",
      "Got MNIST with 52500 training- and 17500 test samples\n",
      "Digit distribution in whole dataset: [6903 7877 6990 7141 6824 6313 6876 7293 6825 6958]\n",
      "Training model.\n",
      "Iteration 1, loss = 0.44156265\n",
      "Iteration 2, loss = 0.21363238\n",
      "Iteration 3, loss = 0.16140911\n",
      "Iteration 4, loss = 0.13016280\n",
      "Iteration 5, loss = 0.10667933\n",
      "Iteration 6, loss = 0.09193744\n",
      "Iteration 7, loss = 0.07891474\n",
      "Iteration 8, loss = 0.06828535\n",
      "Iteration 9, loss = 0.06039063\n",
      "Iteration 10, loss = 0.05365600\n",
      "Iteration 11, loss = 0.04711893\n",
      "Iteration 12, loss = 0.04117964\n",
      "Iteration 13, loss = 0.03707792\n",
      "Iteration 14, loss = 0.03269249\n",
      "Iteration 15, loss = 0.02882466\n",
      "Iteration 16, loss = 0.02595738\n",
      "Iteration 17, loss = 0.02373293\n",
      "Iteration 18, loss = 0.02051003\n",
      "Iteration 19, loss = 0.01810366\n",
      "Iteration 20, loss = 0.01622967\n",
      "Iteration 21, loss = 0.01421112\n",
      "Iteration 22, loss = 0.01333426\n",
      "Iteration 23, loss = 0.01180498\n",
      "Iteration 24, loss = 0.01028507\n",
      "Iteration 25, loss = 0.00937378\n",
      "Iteration 26, loss = 0.00826307\n",
      "Iteration 27, loss = 0.00697747\n",
      "Iteration 28, loss = 0.00713668\n",
      "Iteration 29, loss = 0.00607632\n",
      "Iteration 30, loss = 0.00534278\n",
      "Iteration 31, loss = 0.00446152\n",
      "Iteration 32, loss = 0.00384295\n",
      "Iteration 33, loss = 0.00371255\n",
      "Iteration 34, loss = 0.00355817\n",
      "Iteration 35, loss = 0.00313648\n",
      "Iteration 36, loss = 0.00272385\n",
      "Iteration 37, loss = 0.00491675\n",
      "Iteration 38, loss = 0.00420944\n",
      "Iteration 39, loss = 0.00315976\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "PATH = 'mlp_model.pkl'\n",
    "\n",
    "#only executes if this is run as the 'main'-program but not when it is imported somewhere else\n",
    "if __name__ == '__main__':\n",
    "    print('Fetching and loading MNIST data')\n",
    "    \n",
    "    #sklearn package that loades data from a file or from the web\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    \n",
    "    #Assigning data and labels to X and y\n",
    "    X, y = mnist.data, mnist.target\n",
    "    \n",
    "    #sklearn-package that splits a dataset into test- and trainsets; the 'random_state' parameter is the seed used by the\n",
    "    #random-number-generator that is used to randomize which datapoints are put into test- and trainset, respectively\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X / 255., y, test_size=0.25, random_state=0)\n",
    "\n",
    "    print('Got MNIST with %d training- and %d test samples' % (len(y_train), len(y_test)))\n",
    "    print('Digit distribution in whole dataset:', np.bincount(y.astype('int64')))\n",
    "\n",
    "    clf = None\n",
    "    \n",
    "    #loads model from file if the path exists\n",
    "    if os.path.exists(PATH):\n",
    "        print('Loading model from file.')\n",
    "        clf = joblib.load(PATH).best_estimator_\n",
    "    \n",
    "    else:\n",
    "        print('Training model.')\n",
    "        params = {'hidden_layer_sizes': [(256,), (512,), (128, 256, 128,)]}\n",
    "        \n",
    "        #using the MLP-model from sklearn; verbose=10 means that progress messages are printed; \n",
    "        mlp = MLPClassifier(verbose=10, learning_rate='adaptive')\n",
    "        \n",
    "        #implements a grid search over different network-sizes; this is currently commented out, because it put too big\n",
    "        #a strain on the author's machine's memory; instead clf ist just set equal to mlp this also lead to the\n",
    "        #commenting out of three more lines further down\n",
    "        #clf = GridSearchCV(mlp, params, verbose=10, n_jobs=-1, cv=5)\n",
    "        clf = mlp\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        #print('Finished with grid search with best mean cross-validated score:', clf.best_score_)\n",
    "        #print('Best params appeared to be', clf.best_params_)\n",
    "        joblib.dump(clf, PATH)\n",
    "        #clf = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9999047619047619\n",
      "Test accuracy:  0.9766857142857143\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: ', clf.score(X_train, y_train))\n",
    "print('Test accuracy: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
